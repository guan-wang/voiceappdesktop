# Assessment State Machine Refactoring

## Date: 2026-01-26

## Critical Issues with Current Implementation

### Problem 1: `response.done` â‰  Audio Complete âŒ

**Current Assumption (WRONG):**
```
response.done fires â†’ Audio is complete â†’ Safe to proceed
```

**Reality:**
```
response.done fires â†’ Response created â†’ Audio STILL GENERATING â†’ Audio plays later
```

**Evidence from Terminal:**
```
âœ… Response complete (ID: unknown)           # response.done
ğŸ“Š Assessment response 1/1 completed         # We think it's done
ğŸ” Now generating assessment report...        # Start next step (takes 3-5 sec)
â³ Waiting for acknowledgment audio...        # Wait for audio
âš ï¸ Timeout waiting for ack audio             # Audio hasn't played yet!
```

### Problem 2: Assessment Generation Timing â±ï¸

**Issue:** Generating the assessment report takes 3-5 seconds. During this time:
- Acknowledgment audio is STILL being generated by OpenAI
- By the time we wait for audio, it hasn't fired yet
- Timeout occurs, we proceed anyway
- Audio plays AFTER we've moved on

**Timeline:**
```
T+0s:  response.done fires
T+0s:  Start generating assessment (blocking!)
T+3s:  Still generating...
T+4s:  Finished generating, now wait for audio
T+4s:  Timeout (audio still hasn't arrived)
T+5s:  Proceed to send summary
T+6s:  Acknowledgment audio FINALLY arrives (too late!)
```

### Problem 3: Counter-Based State Tracking ğŸ”¢

**Current Approach:**
```python
if self.assessment_responses_pending == 1:
    self.ack_audio_done.set()  # Acknowledgment audio complete
elif self.assessment_responses_pending == 2:
    self.summary_audio_done.set()  # Summary audio complete
```

**Problem:** `assessment_responses_pending` changes BEFORE previous audio completes!

**Race Condition:**
```
1. Send ack (pending=1)
2. response.done fires
3. Generate assessment (3-5 sec)
4. Send summary (pending=2)  â† UPDATED TOO EARLY!
5. Ack audio arrives, checks pending==2 â†’ Sets WRONG event!
6. Summary audio event set instead of ack audio event
7. Code thinks summary is done, sends goodbye too early
```

### Problem 4: Multiple Responses In Flight ğŸš€

**Error from Terminal:**
```
âŒ API Error: Conversation already has an active response in progress: resp_D2CIBuzHeays2f3ke6ipF
```

**Cause:** We send goodbye while summary response is still being generated.

**OpenAI API Requirement:** Only ONE `response.create` at a time!

---

## Solution: State Machine Architecture

### Key Improvements âœ…

1. **Explicit States** - Clear, named states instead of implicit counters
2. **Response ID Tracking** - Track specific responses, not just counts
3. **Separate Audio from Response** - Acknowledge they're different events
4. **No Premature Updates** - State only changes when truly ready
5. **Event-Driven Flow** - Wait for actual events, not assumptions

### State Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INACTIVE   â”‚ â† Normal interview mode
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ trigger_assessment()
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRIGGERED  â”‚ â† Assessment just triggered
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ send tool output â†’ response created
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACK_GENERATING   â”‚ â† Waiting for ack response
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ audio.delta â†’ audio started
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ACK_SPEAKING    â”‚ â† Acknowledgment audio playing
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ audio_transcript.done â†’ audio complete
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REPORT_GENERATING    â”‚ â† Generating assessment (blocking)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ report generated
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SUMMARY_SENDING     â”‚ â† Sending summary to API
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ audio.delta â†’ audio started
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SUMMARY_SPEAKING    â”‚ â† Summary audio playing
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ audio_transcript.done â†’ audio complete
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GOODBYE_SENDING     â”‚ â† Sending goodbye to API
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ audio.delta â†’ audio started
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GOODBYE_SPEAKING    â”‚ â† Goodbye audio playing
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ audio_transcript.done â†’ audio complete
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COMPLETE   â”‚ â† Assessment delivery done
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Response Tracking

Instead of:
```python
# OLD: Counter-based (fragile)
assessment_responses_pending = 1  # What number are we expecting?
assessment_responses_completed = 0  # How many done?
```

Use:
```python
# NEW: Response ID tracking (robust)
response_trackers = {
    "resp_ABC123": ResponseTracker(
        response_id="resp_ABC123",
        state=ACK_GENERATING,
        audio_started=True,
        audio_complete=False,
        response_complete=True
    ),
    "resp_DEF456": ResponseTracker(
        response_id="resp_DEF456",
        state=SUMMARY_SPEAKING,
        audio_started=True,
        audio_complete=False,
        response_complete=False
    )
}
```

### Event Flow (New Approach)

**Acknowledgment Phase:**
```python
# 1. Trigger assessment
state_machine.trigger_assessment("User reached ceiling at A2")
send_tool_output(websocket, call_id, "Please acknowledge...")

# 2. response.created event
state_machine.start_acknowledgment_response(response_id)
# State: TRIGGERED â†’ ACK_GENERATING

# 3. response.audio.delta (first audio chunk)
state_machine.mark_audio_started(response_id)
# State: ACK_GENERATING â†’ ACK_SPEAKING

# 4. response.audio_transcript.done
state_machine.mark_audio_complete(response_id)
# Audio event fires

# 5. response.done
state_machine.mark_response_complete(response_id)
# Response is done (we don't care, we wait for audio!)

# 6. Wait for audio to ACTUALLY finish
await state_machine.wait_for_audio_complete(response_id, timeout=10.0)
# This returns immediately if audio already complete!

# 7. NOW safe to proceed
state_machine.start_report_generation()
# State: ACK_SPEAKING â†’ REPORT_GENERATING
```

**Report Generation Phase:**
```python
# Generate report (takes 3-5 seconds)
report = assessment_agent.generate_assessment(conversation_history)
verbal_summary = assessment_agent.report_to_verbal_summary(report)

# Check if we can send summary (ack audio must be complete)
if state_machine.can_send_summary():
    send_text_message(websocket, verbal_summary)
    # Wait for response to be created...
```

**Summary Phase:**
```python
# 1. response.created event (for summary)
state_machine.start_summary_response(response_id, verbal_summary)
# State: REPORT_GENERATING â†’ SUMMARY_SENDING

# 2. response.audio.delta (first audio chunk)
state_machine.mark_audio_started(response_id)
# State: SUMMARY_SENDING â†’ SUMMARY_SPEAKING

# 3. response.audio_transcript.done
state_machine.mark_audio_complete(response_id)
# Audio event fires

# 4. Wait for audio to finish
await state_machine.wait_for_audio_complete(response_id, timeout=20.0)

# 5. NOW safe to send goodbye
if state_machine.can_send_goodbye():
    send_text_message(websocket, goodbye_msg)
```

---

## Integration Steps

### Step 1: Add State Machine to InterviewAgent

```python
from assessment_state_machine import AssessmentStateMachine, AssessmentState

class InterviewAgent:
    def __init__(self):
        # ... existing code ...
        
        # REPLACE counter-based tracking:
        # self.assessment_triggered = False
        # self.assessment_responses_pending = 0
        # self.assessment_responses_completed = 0
        # self.ack_audio_done = asyncio.Event()
        # self.summary_audio_done = asyncio.Event()
        
        # WITH state machine:
        self.assessment_state = AssessmentStateMachine()
```

### Step 2: Update trigger_assessment Handler

```python
elif function_name == "trigger_assessment":
    reason = arguments.get("reason", "Ceiling reached")
    
    # Trigger state machine
    if self.assessment_state.trigger_assessment(reason):
        # Clear audio buffer
        await websocket.send(json.dumps({"type": "input_audio_buffer.clear"}))
        
        # Send acknowledgment instruction
        await self.send_tool_output(
            websocket, call_id,
            "Please IMMEDIATELY tell the user: 'í‰ê°€ë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'"
        )
        
        # Note: Don't start generating yet! Wait for audio to complete first.
```

### Step 3: Track Responses by ID

```python
elif event_type == "response.created":
    response_id = event.get("response", {}).get("id")
    
    # Check current state and register response
    if self.assessment_state.current_state == AssessmentState.TRIGGERED:
        self.assessment_state.start_acknowledgment_response(response_id)
    
    # (Similar for other states...)
```

### Step 4: Update Audio Event Handlers

```python
elif event_type == "response.audio.delta":
    response_id = event.get("response_id")
    self.assessment_state.mark_audio_started(response_id)
    
    # ... queue audio for playback ...

elif event_type == "response.audio_transcript.done":
    response_id = event.get("response_id")
    
    # Print transcript (existing logic)
    # ...
    
    # Mark audio complete for this specific response
    self.assessment_state.mark_audio_complete(response_id)
```

### Step 5: Update response.done Handler

```python
elif event_type == "response.done":
    response_id = event.get("response_id", "unknown")
    
    # Track response completion
    self.assessment_state.mark_response_complete(response_id)
    
    # Check state and take appropriate action
    current_state = self.assessment_state.current_state
    
    if current_state == AssessmentState.ACK_SPEAKING:
        # Wait for audio to ACTUALLY complete
        audio_ok = await self.assessment_state.wait_for_audio_complete(
            response_id, timeout=10.0
        )
        
        if audio_ok:
            # NOW generate assessment
            if self.assessment_state.start_report_generation():
                report = self.assessment_agent.generate_assessment(...)
                verbal_summary = self.assessment_agent.report_to_verbal_summary(report)
                
                # Send summary
                await self._send_text_message(websocket, verbal_summary)
                # Response ID will be captured in response.created event
    
    elif current_state == AssessmentState.SUMMARY_SPEAKING:
        # Wait for summary audio to complete
        audio_ok = await self.assessment_state.wait_for_audio_complete(
            response_id, timeout=20.0
        )
        
        if audio_ok and self.assessment_state.can_send_goodbye():
            # Send goodbye
            await self._send_text_message(websocket, goodbye_msg)
    
    elif current_state == AssessmentState.GOODBYE_SPEAKING:
        # Wait for goodbye audio
        await self.assessment_state.wait_for_audio_complete(
            response_id, timeout=10.0
        )
        
        # Mark complete and end session
        self.assessment_state.mark_complete()
        self.should_end_session = True
```

### Step 6: Update Audio Input Handler

```python
async def audio_input_handler(self, websocket):
    while self.is_running and not self.should_end_session:
        # Block input during assessment delivery
        if self.assessment_state.current_state not in [
            AssessmentState.INACTIVE,
            AssessmentState.COMPLETE
        ]:
            await asyncio.sleep(0.1)
            continue
        
        # ... normal audio input handling ...
```

---

## Benefits of State Machine Approach

### 1. **No More Race Conditions** âœ…
- State only updates when truly ready
- No premature counter increments
- Audio completion tied to specific response IDs

### 2. **Clear Flow** âœ…
- Explicit states make flow obvious
- Easy to debug (just check current state)
- Logging shows exact state transitions

### 3. **Proper Synchronization** âœ…
- Wait for ACTUAL audio completion, not assumptions
- Response ID tracking prevents event mismatch
- No "already has an active response" errors

### 4. **Better Error Handling** âœ…
- Can check `can_proceed_to_X()` before actions
- State machine prevents invalid transitions
- Easy to add timeout recovery

### 5. **Maintainable** âœ…
- State transitions documented in enum
- Response tracking centralized
- Easy to add new states if needed

---

## Testing Strategy

### Test Cases:

1. **Normal Flow**
   - Acknowledgment plays completely
   - Summary plays completely
   - Goodbye plays completely
   - No timeouts, no errors

2. **Slow Network**
   - Audio arrives delayed
   - State machine waits correctly
   - No premature transitions

3. **User Interruption**
   - User speaks during summary
   - Audio input blocked correctly
   - Summary completes before goodbye

4. **Early Goodbye**
   - User says "ê°ì‚¬í•©ë‹ˆë‹¤" during summary
   - Graceful early exit
   - No errors

### Debug Logging:

```python
# Print state transitions
ğŸ“Š State: triggered
ğŸ“Š State: ack_generating (ID: ABC123)
ğŸ“Š State: ack_speaking
âœ… Audio complete for ack_generating (ID: ABC123)
ğŸ“Š State: report_generating
ğŸ“Š State: summary_sending (ID: DEF456)
ğŸ“Š State: summary_speaking
âœ… Audio complete for summary_speaking (ID: DEF456)
ğŸ“Š State: goodbye_sending (ID: GHI789)
ğŸ“Š State: goodbye_speaking
âœ… Audio complete for goodbye_speaking (ID: GHI789)
ğŸ“Š State: complete
```

---

## Migration Path

### Phase 1: Add State Machine (Parallel)
- Add `assessment_state_machine.py`
- Keep existing counters
- Log state alongside existing logs
- Verify state transitions match expectations

### Phase 2: Integrate Response ID Tracking
- Capture response IDs in `response.created`
- Update audio handlers to use response IDs
- Keep existing logic, add state machine calls

### Phase 3: Replace Counter Logic
- Remove counter-based checks
- Use state machine `can_X()` methods
- Replace asyncio.Event with state machine waiting

### Phase 4: Cleanup
- Remove old counter variables
- Remove old event flags
- Remove debug logging if desired

---

## Expected Results After Refactoring

âœ… **No silence gaps** - Acknowledgment plays immediately  
âœ… **Full summary delivery** - Summary plays completely before goodbye  
âœ… **No timeouts** - Proper audio completion detection  
âœ… **No API errors** - One response at a time  
âœ… **Clean state transitions** - Clear logging of flow  
âœ… **Robust synchronization** - Event-driven, not time-based  

---

## Files to Modify

1. **`assessment_state_machine.py`** âœ… (Created)
2. **`interview_agent.py`** - Integrate state machine
3. **`MDs/BUG_FIX_AUDIO_TIMING.md`** - Update with new architecture

---

## Conclusion

The current counter-based approach is fundamentally flawed because:
1. It assumes `response.done` = audio complete (FALSE)
2. It updates state before audio completes (race condition)
3. It can't handle delayed/reordered events (fragile)

The state machine approach fixes this by:
1. Tracking responses by ID (robust)
2. Waiting for actual audio completion events (event-driven)
3. Explicit states with clear transitions (maintainable)

This refactoring will eliminate all timing issues and provide a solid foundation for future enhancements.
